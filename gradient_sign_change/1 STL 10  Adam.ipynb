{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T00:21:34.034604Z",
     "start_time": "2019-06-18T00:21:22.247940Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import lib\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "from keras.utils import to_categorical\n",
    "plt.style.use('seaborn-white'); os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "np.random.seed(678); tf.set_random_seed(678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T00:21:34.063540Z",
     "start_time": "2019-06-18T00:21:34.053387Z"
    },
    "code_folding": [
     1,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# prepare STL 10\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T00:21:34.112248Z",
     "start_time": "2019-06-18T00:21:34.077324Z"
    },
    "code_folding": [
     47,
     87
    ]
   },
   "outputs": [],
   "source": [
    "# activation functions\n",
    "def tf_elu(x):     return tf.nn.elu(x)\n",
    "def d_tf_elu(x):   return tf.cast(tf.greater(x,0),tf.float32) +  tf.exp(tf.cast(tf.less_equal(x,0),tf.float32) * x)\n",
    "def tf_iden(x):    return x\n",
    "def d_tf_iden(x):  return tf.ones_like(x)\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "class CNN():\n",
    "    \n",
    "    def __init__(self,k,inc,out,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.padding    = 'SAME'\n",
    "        self.stride     = 1\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=0.05))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "    \n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.padding= padding; self.stride = stride\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,self.stride,self.stride,1],padding=self.padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,iter_num):\n",
    "        grad_part_1 = gradient \n",
    "        grad_part_2 = self.d_act(self.layer) \n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "\n",
    "        grad     = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = self.w.shape,out_backprop = grad_middle,\n",
    "            strides=[1,self.stride,self.stride,1],padding=self.padding\n",
    "        )/batch_size\n",
    "\n",
    "        grad_pass = tf.nn.conv2d_backprop_input(input_sizes = self.input.shape,filter= self.w,  out_backprop = grad_middle,\n",
    "            strides=[1,self.stride,self.stride,1],padding=self.padding\n",
    "        )\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-tf.pow(beta1,iter_num))\n",
    "        v_hat = self.v / (1-tf.pow(beta2,iter_num))\n",
    "        update_w.append(tf.assign( self.w,self.w - learning_rate*( m_hat/(tf.sqrt(v_hat) + adam_e)   )))\n",
    "        return grad_pass,update_w  \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis=None):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = (0,1,2)\n",
    "        \n",
    "    def feedforward(self,input,training_phase,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "class tf_layer_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.axis        = (1,2,3)\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w * self.c)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T00:21:38.540928Z",
     "start_time": "2019-06-18T00:21:38.434322Z"
    }
   },
   "outputs": [],
   "source": [
    "! start ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T00:22:06.083455Z",
     "start_time": "2019-06-18T00:21:55.703486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) (5000, 10) -11.595098265964817 15.777090090299724\n",
      "(8000, 96, 96, 3) (8000, 10) -10.553357891447178 22.92614277238906\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "x_train,y_train = read_all_images('../Dataset/STL10/stl10_binary/train_x.bin'),read_labels('../Dataset/STL10/stl10_binary/train_y.bin')\n",
    "x_test,y_test   = read_all_images('../Dataset/STL10/stl10_binary/test_x.bin'),read_labels('../Dataset/STL10/stl10_binary/test_y.bin')\n",
    "\n",
    "y_train = to_categorical(y_train-1)\n",
    "y_test  = to_categorical(y_test-1)\n",
    "\n",
    "x_train = (x_train-x_train.min((1,2),keepdims=True))/(x_train.max((1,2),keepdims=True)-x_train.min((1,2),keepdims=True))\n",
    "x_train = (x_train-x_train.mean((1,2),keepdims=True))/(x_train.std((1,2),keepdims=True))\n",
    "x_test = (x_test-x_test.min((1,2),keepdims=True))/(x_test.max((1,2),keepdims=True)-x_test.min((1,2),keepdims=True))\n",
    "x_test = (x_test-x_test.mean((1,2),keepdims=True))/(x_test.std((1,2),keepdims=True))\n",
    "\n",
    "print(x_train.shape,y_train.shape,x_train.min(),x_train.max())\n",
    "print(x_test.shape,y_test.shape,x_test.min(),x_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T00:22:46.648678Z",
     "start_time": "2019-06-18T00:22:46.643691Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare hyper parameter\n",
    "learning_rate = 0.0008 ; beta1 = 0.9; beta2 = 0.999; adam_e = 1e-8\n",
    "num_epoch     = 30    ; batch_size = 50 ; print_size = 1; \n",
    "channel_sizes = 96 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T00:22:08.502015Z",
     "start_time": "2019-06-05T00:22:08.313976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# declare layer\n",
    "avg_acc_train = 0; avg_acc_test  = 0; train_acc = [];test_acc = []\n",
    "avg_lss_train = 0; avg_lss_test  = 0; train_lss = [];test_lss = []\n",
    "\n",
    "l1   = CNN(3,3,channel_sizes)\n",
    "l2   = CNN(3,channel_sizes,channel_sizes)\n",
    "l3   = CNN(3,channel_sizes,channel_sizes)\n",
    "\n",
    "l4   = CNN(3,channel_sizes,channel_sizes)\n",
    "l5   = CNN(3,channel_sizes,channel_sizes)\n",
    "l6   = CNN(3,channel_sizes,channel_sizes)\n",
    "\n",
    "l7   = CNN(3,channel_sizes,channel_sizes)\n",
    "l8   = CNN(1,channel_sizes,channel_sizes)\n",
    "l9   = CNN(1,channel_sizes,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T00:22:08.931126Z",
     "start_time": "2019-06-05T00:22:08.502973Z"
    }
   },
   "outputs": [],
   "source": [
    "# graph\n",
    "x = tf.placeholder(shape=[batch_size,96,96,3],dtype=tf.float32)\n",
    "y = tf.placeholder(shape=[batch_size,10],     dtype=tf.float32)\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "iter_num = tf.placeholder_with_default(1.0,())\n",
    "\n",
    "layer1  = l1. feedforward(x,padding='VALID',stride=2)    \n",
    "layer2  = l2.feedforward(layer1,padding='VALID') \n",
    "layer3  = l3.feedforward(layer2,padding='VALID',stride=2); \n",
    "\n",
    "layer4  = l4.feedforward(layer3,padding='VALID');      \n",
    "layer5  = l5.feedforward(layer4,padding='VALID');      \n",
    "layer6  = l6.feedforward(layer5,padding='VALID',stride=2)\n",
    "\n",
    "layer7  = l7.feedforward(layer6,padding='VALID')\n",
    "layer8  = l8.feedforward(layer7)\n",
    "layer9  = l9.feedforward(layer8)\n",
    "\n",
    "final_global = tf.reduce_mean(layer9,[1,2])\n",
    "final_soft   = tf_softmax(final_global) ; \n",
    "cost         = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_global,labels=y))\n",
    "accuracy     = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(final_soft, 1), tf.argmax(y, 1)),tf.float32) )\n",
    "\n",
    "gradient     = tf.tile((final_soft-y)[:,None,None,:],(1,6,6,1))\n",
    "\n",
    "grad9, grad9_up  = l9. backprop(gradient,iter_num)\n",
    "grad8, grad8_up  = l8. backprop(grad9,iter_num)\n",
    "grad7, grad7_up  = l7. backprop(grad8,iter_num)\n",
    "\n",
    "grad6, grad6_up  = l6. backprop(grad7,iter_num)\n",
    "grad5, grad5_up  = l5. backprop(grad6,iter_num)\n",
    "grad4, grad4_up  = l4. backprop(grad5,iter_num)\n",
    "\n",
    "grad3,grad3_up   = l3. backprop(grad4,iter_num)\n",
    "grad2,grad2_up   = l2. backprop(grad3,iter_num)\n",
    "grad1,grad1_up   = l1. backprop(grad2,iter_num)\n",
    "\n",
    "grad_update =  grad9_up + grad8_up + grad7_up +\\\n",
    "               grad6_up + grad5_up + grad4_up +\\\n",
    "               grad3_up + grad2_up + grad1_up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T00:29:10.925077Z",
     "start_time": "2019-06-18T00:29:09.689731Z"
    }
   },
   "outputs": [],
   "source": [
    "# start the session\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T00:26:13.198422Z",
     "start_time": "2019-06-05T00:22:10.004245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: 1\tTrain Acc: 0.12219999950379133\tTrain Cost: 2.276678659915924\tTest Acc: 0.15237499957438558\tTest Cost: 2.2773143887519836\tLR: 0.0008\n",
      "Current: 2\tTrain Acc: 0.20780000001192092\tTrain Cost: 2.152440881729126\tTest Acc: 0.25824999948963523\tTest Cost: 2.023808221518993\tLR: 0.0008\n",
      "Current: 3\tTrain Acc: 0.2935999993979931\tTrain Cost: 1.9185413479804994\tTest Acc: 0.35125000067055223\tTest Cost: 1.7913942433893681\tLR: 0.0008\n",
      "Current: 4\tTrain Acc: 0.3696000011265278\tTrain Cost: 1.6899959290027617\tTest Acc: 0.3793750010430813\tTest Cost: 1.6424052387475967\tLR: 0.0008\n",
      "Current: 5\tTrain Acc: 0.4208000001311302\tTrain Cost: 1.5723451638221742\tTest Acc: 0.4302499983459711\tTest Cost: 1.5321230098605156\tLR: 0.0008\n",
      "Current: 6\tTrain Acc: 0.4697999969124794\tTrain Cost: 1.441460303068161\tTest Acc: 0.45399999879300595\tTest Cost: 1.4731350645422936\tLR: 0.0008\n",
      "Current: 7\tTrain Acc: 0.49679999858140944\tTrain Cost: 1.3626715815067292\tTest Acc: 0.4666249996051192\tTest Cost: 1.4415630236268044\tLR: 0.0008\n",
      "Current: 8\tTrain Acc: 0.5253999978303909\tTrain Cost: 1.3050576329231263\tTest Acc: 0.49737499803304674\tTest Cost: 1.3784730173647404\tLR: 0.0008\n",
      "Current: 9\tTrain Acc: 0.5459999996423721\tTrain Cost: 1.2336915093660354\tTest Acc: 0.486999998986721\tTest Cost: 1.4053704395890236\tLR: 0.0008\n",
      "Current: 10\tTrain Acc: 0.569600006043911\tTrain Cost: 1.1670187908411025\tTest Acc: 0.5096250012516975\tTest Cost: 1.333234290778637\tLR: 0.0008\n",
      "Current: 11\tTrain Acc: 0.5914000028371811\tTrain Cost: 1.1231373858451843\tTest Acc: 0.5279999999329448\tTest Cost: 1.2985814213752747\tLR: 0.0008\n",
      "Current: 12\tTrain Acc: 0.6104000017046929\tTrain Cost: 1.0847940617799758\tTest Acc: 0.5259999999776482\tTest Cost: 1.308746551722288\tLR: 0.0008\n",
      "Current: 13\tTrain Acc: 0.6352000039815903\tTrain Cost: 1.025928025841713\tTest Acc: 0.5302500009536744\tTest Cost: 1.2997259255498648\tLR: 0.0008\n",
      "Current: 14\tTrain Acc: 0.6518000030517578\tTrain Cost: 0.9695255368947983\tTest Acc: 0.5565000008791685\tTest Cost: 1.2442109104245902\tLR: 0.0008\n",
      "Current: 15\tTrain Acc: 0.6642000055313111\tTrain Cost: 0.9444942742586135\tTest Acc: 0.5528750011697412\tTest Cost: 1.2632424123585224\tLR: 0.0008\n",
      "Current: 16\tTrain Acc: 0.6980000019073487\tTrain Cost: 0.8764610385894775\tTest Acc: 0.5451250037178397\tTest Cost: 1.292837917804718\tLR: 0.0008\n",
      "Current: 17\tTrain Acc: 0.7060000020265579\tTrain Cost: 0.8390097397565842\tTest Acc: 0.5631250008940697\tTest Cost: 1.2670864243060351\tLR: 0.0008\n",
      "Current: 18\tTrain Acc: 0.7076000016927719\tTrain Cost: 0.8190081083774566\tTest Acc: 0.5252499995753169\tTest Cost: 1.376945023611188\tLR: 0.0008\n",
      "Current: 19\tTrain Acc: 0.7328000003099442\tTrain Cost: 0.7752523905038834\tTest Acc: 0.5423749988898635\tTest Cost: 1.3234829109162092\tLR: 0.0008\n",
      "Current: 20\tTrain Acc: 0.7378000050783158\tTrain Cost: 0.7502715450525284\tTest Acc: 0.563000000268221\tTest Cost: 1.2750871423631907\tLR: 0.0008\n",
      "Current: 21\tTrain Acc: 0.7446000003814697\tTrain Cost: 0.722763966023922\tTest Acc: 0.5647500034421682\tTest Cost: 1.293972658365965\tLR: 0.0008\n",
      "Current: 22\tTrain Acc: 0.7783999985456467\tTrain Cost: 0.6470482909679413\tTest Acc: 0.5646250007674098\tTest Cost: 1.2997372705489396\tLR: 0.0008\n",
      "Current: 23\tTrain Acc: 0.7727999985218048\tTrain Cost: 0.6529907268285752\tTest Acc: 0.5725000038743019\tTest Cost: 1.2658485058695077\tLR: 0.0008\n",
      "Current: 24\tTrain Acc: 0.7979999953508377\tTrain Cost: 0.5917030581831932\tTest Acc: 0.5606249995529652\tTest Cost: 1.37631110586226\tLR: 0.0008\n",
      "Current: 25\tTrain Acc: 0.82019999563694\tTrain Cost: 0.5363407957553864\tTest Acc: 0.5593750003725291\tTest Cost: 1.4031985379755496\tLR: 0.0008\n",
      "Current: 26\tTrain Acc: 0.8213999950885773\tTrain Cost: 0.5198342373967171\tTest Acc: 0.5547500014305115\tTest Cost: 1.3911744594573974\tLR: 0.0008\n",
      "Current: 27\tTrain Acc: 0.8471999913454056\tTrain Cost: 0.46523026570677756\tTest Acc: 0.55250000115484\tTest Cost: 1.4717375434935094\tLR: 0.0008\n",
      "Current: 28\tTrain Acc: 0.8487999951839447\tTrain Cost: 0.4536080828309059\tTest Acc: 0.5635000014677644\tTest Cost: 1.431677796691656\tLR: 0.0008\n",
      "Current: 29\tTrain Acc: 0.8687999969720841\tTrain Cost: 0.403112830221653\tTest Acc: 0.5471249988302589\tTest Cost: 1.6041061837226152\tLR: 0.0008\n",
      "Current: 30\tTrain Acc: 0.8621999955177307\tTrain Cost: 0.41952731072902677\tTest Acc: 0.5496250012889504\tTest Cost: 1.5704649161547422\tLR: 0.0008\n"
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "for iter in range(1,num_epoch+1):\n",
    "    for current_batch_index in range(0,len(x_train),batch_size):\n",
    "        current_data  = x_train[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = y_train[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,cost,grad_update],feed_dict={x:current_data,y:current_label,iter_num:iter})\n",
    "        sys.stdout.write('Current Iter : '+str(iter)+'/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(x_train)) + ' acc : '+str(sess_results[0]) + ' cost : '+str(sess_results[1])+ '\\r')\n",
    "        sys.stdout.flush(); \n",
    "        avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        avg_lss_train = avg_lss_train + sess_results[1]\n",
    "    for current_batch_index in range(0,len(x_test), batch_size):\n",
    "        current_data  = x_test[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = y_test[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,cost],feed_dict={x:current_data,y:current_label,is_train:False})\n",
    "        sys.stdout.write('Current Iter : '+str(iter)+'/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(x_test)) + ' acc : '+str(sess_results[0]) + ' cost : '+str(sess_results[1])+ '\\r')\n",
    "        sys.stdout.flush(); \n",
    "        avg_acc_test = avg_acc_test + sess_results[0]\n",
    "        avg_lss_test = avg_lss_test + sess_results[1]\n",
    "    # ======================== print reset ========================  \n",
    "    print(\"Current: \"+ str(iter) + \n",
    "          \"\\tTrain Acc: \"  + str(avg_acc_train/(len(x_train)/batch_size)) + \n",
    "          \"\\tTrain Cost: \" + str(avg_lss_train/(len(x_train)/batch_size)) + \n",
    "          \"\\tTest Acc: \"   + str(avg_acc_test/(len(x_test)/batch_size)) + \n",
    "          \"\\tTest Cost: \"  + str(avg_lss_test/(len(x_test)/batch_size)) + \n",
    "          \"\\tLR: \" + str(learning_rate) )\n",
    "    avg_acc_train   = 0 ; avg_acc_test  = 0 ; avg_lss_train = 0 ; avg_lss_test  = 0\n",
    "    x_train,y_train = shuffle(x_train,y_train); x_test,y_test   = shuffle(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T00:12:01.633084Z",
     "start_time": "2019-06-05T00:12:01.531955Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T00:36:50.961889Z",
     "start_time": "2019-06-18T00:36:50.461923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0001981139 0.050436947\n",
      "(3, 3, 25, 55)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD0CAYAAABgk2Y8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAARjUlEQVR4nO3dfZBVd33H8fcSwkNboO20uGocUx/6HeqIHWnjA6zQEUWwltZOOi20RVMJpUzxqaOJrDqZoUOsBkdqRbuaEiSdTqU+FSXBUYfCmha1aQtj+k1xdGra4KCVhRYBge0f96y5ud7dvSx7dpdf3q8ZZs79nt/Z/Z6TH58999zfkq7BwUEkSWWZNtkNSJLGn+EuSQUy3CWpQIa7JBXIcJekAk2f7AYiYibwy8CjwKVJbkeSrhXXAU8GvpyZ51t3Tnq40wj2Q5PdhCRdo3qAw63FqRDujwLce++9dHd3T3YvknRNOHHiBGvXroUqQ1tNhXC/BNDd3c0NN9ww2b1I0rWm7eNsP1CVpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAU2GduyQV78bbPtO2/s07X1nL9/POXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAJ19O+5R8TtwK8BM4APAAeBXcAgcAzYlJmXI2I9sAG4CGzNzH0RMRvYA8wHzgDrMvPkeJ+IJOkxo965R8Qy4MXAYmAp8DRgO9CbmT1AF7A6IrqBzdW4FcC2iJgJbASOVmN3A701nIckqUknj2VWAEeBTwB/D+wDFtG4ewfYDywHbgL6M/N8Zg4Ax4GFwBLgvpaxkqQadfJY5meApwO/Cvwc8GlgWmYOVvvPAPOAucBA03Ht6kM1SVKNOgn37wL/npkXgIyIczQezQyZA5wCTlfbI9WHapKkGnXyWOYw8IqI6IqIpwA/Dny+ehYPsBI4BBwBeiJiVkTMAxbQ+LC1H1jVMlaSVKNR79yrFS8voRHe04BNwDeAvoiYATwE7M3MSxGxg0Z4TwO2ZOa5iNgJ3BMRh4ELwJqazkWSVOloKWRmvqVNeWmbcX1AX0vtLHDzmLqTJI2Jv8QkSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kq0PROBkXEg8BA9fIbwJ8Cu4BB4BiwKTMvR8R6YANwEdiamfsiYjawB5gPnAHWZebJcT0LSdLjjHrnHhGzADJzWfXntcB2oDcze4AuYHVEdAObgcXACmBbRMwENgJHq7G7gd56TkWSNKSTO/fnAT8WEQeq8W8DFgEHq/37gZcDl4D+zDwPnI+I48BCYAnwZ01j3z5+7UuS2ukk3M8C7wE+DDybRkB3ZeZgtf8MMA+Yy2OPboarD9UkSTXqJNwfBo5XYf5wRHyXxp37kDnAKeB0tT1SfagmSapRJ6tlbgHuAoiIp9C4Ez8QEcuq/SuBQ8ARoCciZkXEPGABjQ9b+4FVLWMlSTXq5M79I8CuiDhMY3XMLcB3gL6ImAE8BOzNzEsRsYNGeE8DtmTmuYjYCdxTHX8BWFPHiUiSHjNquGfmcIG8tM3YPqCvpXYWuHmsDUqSrpy/xCRJBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgaZ3Migi5gNfBV4GXAR2AYPAMWBTZl6OiPXAhmr/1szcFxGzgT3AfOAMsC4zT477WUiSHmfUO/eIuB74EPD9qrQd6M3MHqALWB0R3cBmYDGwAtgWETOBjcDRauxuoHf8T0GS1KqTxzLvAT4I/Hf1ehFwsNreDywHbgL6M/N8Zg4Ax4GFwBLgvpaxkqSajRjuEfEa4GRm3t9U7srMwWr7DDAPmAsMNI1pVx+qSZJqNtoz91uAwYhYDvwijUcr85v2zwFOAaer7ZHqQzVJUs1GvHPPzJdk5tLMXAb8C/D7wP6IWFYNWQkcAo4APRExKyLmAQtofNjaD6xqGStJqtlYlkK+GbgjIh4AZgB7M/MEsINGeH8B2JKZ54CdwHMi4jBwK3DH+LQtSRpJR0shAaq79yFL2+zvA/paameBm8fanCRpbPwlJkkqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKNH20ARFxHdAHBHAJeC3QBewCBoFjwKbMvBwR64ENwEVga2bui4jZwB5gPnAGWJeZJ2s4F0lSpZM791cBZOZi4B3A9upPb2b20Aj61RHRDWwGFgMrgG0RMRPYCBytxu4Gesf9LCRJjzNquGfmJ4Fbq5dPB74NLAIOVrX9wHLgJqA/M89n5gBwHFgILAHuaxkrSapRR8/cM/NiRNwD/DmwF+jKzMFq9xlgHjAXGGg6rF19qCZJqlHHH6hm5jrg52k8f5/dtGsOcAo4XW2PVB+qSZJqNGq4R8TvRcTt1cuzwGXgKxGxrKqtBA4BR4CeiJgVEfOABTQ+bO0HVrWMlSTVaNTVMsDHgb+KiH8ArgfeADwE9EXEjGp7b2ZeiogdNMJ7GrAlM89FxE7gnog4DFwA1tRxIpKkx4wa7pn5f8Bvtdm1tM3YPhqPbZprZ4Gbx9qgJOnK+UtMklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAk0faWdEXA/cDdwIzAS2Al8DdgGDwDFgU2Zejoj1wAbgIrA1M/dFxGxgDzAfOAOsy8yT9ZyKJGnIaHfuvwt8NzN7gJXA+4HtQG9V6wJWR0Q3sBlYDKwAtkXETGAjcLQauxvorec0JEnNRgv3jwFvb3p9EVgEHKxe7weWAzcB/Zl5PjMHgOPAQmAJcF/LWElSzUZ8LJOZ/wsQEXOAvTTuvN+TmYPVkDPAPGAuMNB0aLv6UE2SVLNRP1CNiKcBXwQ+mpl/DVxu2j0HOAWcrrZHqg/VJEk1GzHcI+JJwAHgrZl5d1V+MCKWVdsrgUPAEaAnImZFxDxgAY0PW/uBVS1jJUk1G/GxDPA24KeAt0fE0LP31wM7ImIG8BCwNzMvRcQOGuE9DdiSmeciYidwT0QcBi4Aa2o5C0nS44z2zP31NMK81dI2Y/uAvpbaWeDmq2lQknTl/CUmSSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgo0vZNBEfEC4F2ZuSwingXsAgaBY8CmzLwcEeuBDcBFYGtm7ouI2cAeYD5wBliXmSdrOA9JUpNR79wj4i3Ah4FZVWk70JuZPUAXsDoiuoHNwGJgBbAtImYCG4Gj1djdQO/4n4IkqVUnj2W+Dry66fUi4GC1vR9YDtwE9Gfm+cwcAI4DC4ElwH0tYyVJNRs13DPz74AfNJW6MnOw2j4DzAPmAgNNY9rVh2qSpJqN5QPVy03bc4BTwOlqe6T6UE2SVLOxhPuDEbGs2l4JHAKOAD0RMSsi5gELaHzY2g+sahkrSarZWML9zcAdEfEAMAPYm5kngB00wvsLwJbMPAfsBJ4TEYeBW4E7xqdtSdJIOloKmZnfBF5YbT8MLG0zpg/oa6mdBW6+6i4lSVfEX2KSpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqUEf/KqQkPRHdeNtnrviYb975yho6uXKGuySNo7H8QKiD4S7pCW+qBPJ4MtwlTXklhm/dDHdJtbnSUJ4qz6tLYLhLmjK8Qx8/hrukjhm+1w7DXXqCMqjLZrhLhTPEn5gMd+kaY1irE7WHe0RMAz4APA84D7wuM4/X/X2la4VhrTpMxJ37rwOzMvNFEfFC4C5g9QR8X+mKDBeywy3PM5Q1lU1EuC8B7gPIzH+MiF9q2X8dwIkTJyagFV2rlrzri23rh9/6K1c0fixu/OOPjtvXklo98sgjYzquKTOva7d/IsJ9LjDQ9PpSREzPzIvV6ycDrF27dgJa0bVq5jD1lx7YekXjpalmuDl8BZ4MfL21OBHhfhqY0/R6WlOwA3wZ6AEeBS5NQD+SVILraAT7l9vtnIhw7wdeBfxt9cz9aPPOzDwPHJ6APiSpND9yxz5kIsL9E8DLIuJLQBfw2gn4npL0hNY1ODg42T10JCJmA3uA+cAZYF1mnmwZ80bgt6uXn83MO4Y7rnoX8T7gInAgM++oq69q3M8CXwKem5nnIuI24BXV7p8EujOzOyJeDbwb+Fa1752ZeXCCeuoCHgH+oxryQGbePgWu1bzquLnADOBNmfnAJF+rSZ9XEbEe2FB9r62Zua/OeXWVfdU2t66ip1rm1WjLvyPiVcA7ql7uzsy+4Y6JiGcBu4BB4BiwKTMvd9LHtfS/2dsIHM3MHmA30Nu8MyKeAawFXgy8CHh5RCwc4bgPAmtorOZ5QUQ8v46+qt5WAAeAJw3VMvPOzFyWmctoTPp11a7nA28Z2jeWv4Bj7Ql4JvDPTd/79qo+qdcKeBPw+cxcCrwG+IuqPpnXalLnVUR0A5uBxcAKYFtEzKx5Xo25L+qdW2Ptqa559cPl38BtNJZ/D/VyPfBe4OXAUuDWqr/hjtkO9Fbn1sUVLCO/lsL9h0sqgf3A8pb93wJekZmXqp9s1wPn2h0XEXOBmZn59cwcBO4HXlpTXwCXq/r/tO6o7hK+l5n3V6VFwC0RcSgi7oqIsTw6G2tPi4CnRsQXI+Kz0TAVrtV7gQ9V29Np/Hcd6neyrtVkz6ubgP7MPJ+ZA8BxYOHQzprm1dX0VefcGmtPdc2rxy3/BpqXfy8Ajmfm9zLzAo3PG3tGOGYRMPTDZbj52daU/OcHIuIPgDe2lL/NY0sqzwDzmndm5g+A71Rv/94NPJiZD1cTqPW4uTRW8dBUf0YdfVW9fa46vt2XvR34nabXnwM+CXyDxl3NHwLvn6CeHgW2ZebHImIJjbesv8EkX6vMPFXVuque3lDtmsxrNdnzqnWJceuYq5pXNfQ1LnNrPHsar3nVxkjLv4e7Pm2PAbqqH3zDnduwpmS4Z+ZHgI801yLi4zy2pHIOcKr1uIiYBdxN4yL8UVU+3ea41uWZbb/eePU1nIj4BeBUyz/HcHfTpPsU8JsT2NNXaDwHJDMPR8RTaVzLqXCtngv8DfAnTW+TJ/NaTfa8GvZ7jce8qqGvrzEOc6uGa3XV86qNkZZ/D9dL22Mi4nKbsR25lh7L9AOrqu2VwKHmndUd+6eAf83MDZl5abjjMvM0cCEinlkdt6L1641XX6NYTuOtVvM5/FtE3FCVXgp8dQJ7eifV3UtEPA/4z+pt7KReqyqsPgasycz9VW2yr9Vkz6sjQE9EzKo+GFxA4wM3qG9eXU1fdc6tMfVU47z6YT/xo8u/HwKeHRE/HREzgJcAD4xwzIMRsWyEcxvWlLxzH8ZO4J6IOAxcoPEhDBHxJhrP0K6j8QHFzIhYWR1z+3DH0XirdW913IHM/Kc6+srMT49wbNB4CwhAZg5GxOuAj0fE92nc7fRNYE93Ansi4pU07rJeU9Un+1ptA2YB76sejQxk5upJvlaTPq8iYgeNv+zTgC2ZOfTMuK55Nea+IqLOuTXWnuqaVz+y/Dsi1gA/kZl/WfV1f9XL3Zn5XxEx3JLxNwN91Q+Ch4C9nTZxzSyFlCR17lp6LCNJ6pDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgf4fZPtqU8hdzwsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see \n",
    "temp = tf.random_normal([3,3,25,55],stddev=0.05)\n",
    "temp_post = tf.where(temp>0,tf.zeros_like(temp),tf.ones_like(temp)) * temp\n",
    "\n",
    "temp = temp.eval()\n",
    "temp_post = temp_post.eval()\n",
    "print(temp.mean(),temp.std())\n",
    "print(temp_post.shape)\n",
    "\n",
    "plt.hist(temp.flatten(),bins=50); plt.show()\n",
    "plt.hist(temp_post.flatten(),bins=50); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
