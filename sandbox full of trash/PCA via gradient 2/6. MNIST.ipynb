{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T11:26:02.332975Z",
     "start_time": "2019-04-10T11:25:49.515406Z"
    },
    "code_folding": [
     22
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import make_moons,make_classification,make_regression,make_circles\n",
    "import sys\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "np.random.seed(23)\n",
    "np.set_printoptions(precision=3,suppress=True)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def _sym_decorrelation(W):\n",
    "    \"\"\" Symmetric decorrelation\n",
    "    i.e. W <- (W * W.T) ^{-1/2} * W\n",
    "    \"\"\"\n",
    "    s, u = np.linalg.eigh(np.dot(W, W.T))\n",
    "    # u (resp. s) contains the eigenvectors (resp. square roots of\n",
    "    # the eigenvalues) of W * W.T\n",
    "    return np.dot(np.dot(u * (1./(np.sqrt(s+1e-8))+1e-8), u.T), W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T11:26:10.037655Z",
     "start_time": "2019-04-10T11:26:09.453232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../Dataset/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ../../Dataset/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../Dataset/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../Dataset/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784) (55000, 10) 1.0 0.0\n",
      "(5000, 784) (5000, 10) 1.0 0.0\n",
      "(10000, 784) (10000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "mnist = input_data.read_data_sets('../../Dataset/MNIST/', one_hot=True)\n",
    "train_data,train_label,val_data,val_label,test_data,test_label = mnist.train.images,mnist.train.labels,mnist.validation.images,mnist.validation.labels,mnist.test.images, mnist.test.labels\n",
    "print(train_data.shape,train_label.shape,train_data.max(),train_data.min())\n",
    "print(val_data.shape,val_label.shape,val_data.max(),val_data.min())\n",
    "print(test_data.shape,test_label.shape,test_data.max(),test_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T11:26:02.442592Z",
     "start_time": "2019-04-10T11:25:48.892Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#  create class\n",
    "def arctan(x):  return tf.arctan(x)\n",
    "def tan(x)   :  return tf.tan(x)\n",
    "def d_arctan(x):return 1/(1+x**2)\n",
    "def d_tanh(x):  return 1/tf.cos(x)\n",
    "\n",
    "class FNN():\n",
    "    \n",
    "    def __init__(self,input,output,act,d_act):\n",
    "        self.w = tf.Variable(tf.random.normal())\n",
    "        self.mw,self.mv = np.zeros_like()\n",
    "        \n",
    "        self.a = np.ones(output)\n",
    "        self.b = np.ones(output)\n",
    "        self.c = np.zeros(output)\n",
    "        \n",
    "        self.act  = act\n",
    "        self.d_act= d_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T23:07:35.364085Z",
     "start_time": "2019-04-10T23:07:35.318944Z"
    },
    "code_folding": [
     8,
     30,
     49,
     89,
     92,
     95
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tf_arctan(x): return tf.atan(x)\n",
    "def tf_tan(x)   : return tf.tan(x)\n",
    "\n",
    "def d_tf_arctan(x): return 1/(1+x**2)\n",
    "def d_tf_tan(x):    return 1/(tf.cos(x)**2)\n",
    "\n",
    "class PCA_Layer():\n",
    "\n",
    "    def __init__(self,inc,outc,act=tf_arctan,d_act=d_tf_arctan):\n",
    "        \n",
    "        if outc == 1:\n",
    "            self.w = tf.Variable(self.norm(tf.random_normal([inc,outc],stddev=0.05,seed=2)))\n",
    "        else:\n",
    "            self.w = tf.Variable(self.sym_decorrelation(tf.random_normal([inc,outc],stddev=0.05,seed=2)))\n",
    "        self.a = tf.Variable(tf.ones([outc]))\n",
    "        self.b = tf.Variable(tf.ones([outc]))\n",
    "        self.c = tf.Variable(tf.zeros([outc]))\n",
    "        \n",
    "        self.mw,self.vw = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.ma,self.va = tf.Variable(tf.zeros_like(self.a)),tf.Variable(tf.zeros_like(self.a))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.mc,self.vc = tf.Variable(tf.zeros_like(self.c)),tf.Variable(tf.zeros_like(self.c))\n",
    "        \n",
    "        self.act,self.d_act = act,d_act\n",
    "\n",
    "    def feedforward_linear(self,input=None):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.matmul(self.input,self.w) \n",
    "        loss = self.w @ tf.transpose(self.input) @ self.input @ self.w\n",
    "        return self.layer,loss\n",
    "    def backprop_linear(self):\n",
    "        gradw      = -2* tf.transpose(self.input) @ self.input @ self.w\n",
    "        grad_pass  = -2*self.input@self.w@tf.transpose(self.w)\n",
    "        \n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.mw,self.mw*beta1 + (1-beta1) * (gradw)   ))\n",
    "        update_w.append(tf.assign( self.vw,self.vw*beta2 + (1-beta2) * (gradw ** 2)   ))\n",
    "        m_hatw = self.mw / (1-beta1)\n",
    "        v_hatw = self.vw / (1-beta2)\n",
    "        adam_midw = m_hatw *  learning_rate/(tf.sqrt(v_hatw) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,self.sym_decorrelation(tf.subtract(self.w,adam_midw ))))\n",
    "        \n",
    "        return grad_pass,update_w\n",
    "\n",
    "    def feedforward_nonlinear(self,input=None):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.matmul(self.input,self.w) \n",
    "        self.layerA = self.a*self.act(self.b*self.layer) + self.c\n",
    "        loss = self.w @ tf.transpose(self.input) @ self.input @ self.w\n",
    "        return self.layerA,loss\n",
    "    def backprop_nonlinear(self,gradient):\n",
    "        \n",
    "        grada = tf.reduce_mean(gradient * self.act(self.b*self.layer),0)\n",
    "        gradb = tf.reduce_mean(gradient * self.a * self.d_act(self.b*self.layer) * self.layer,0)\n",
    "        gradc = tf.reduce_mean(gradient,0)\n",
    "        gradw = tf.transpose(self.input) @ (gradient * self.a * self.d_act(self.b*self.layer) * self.b) - 2 * tf.transpose(self.input) @ self.input @ self.w\n",
    "        grad_pass = (gradient * self.a * self.d_act(self.b*self.layer) * self.b) @ tf.transpose(self.w) - 2 * self.input@self.w@tf.transpose(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.mw,self.mw*beta1 + (1-beta1) * (gradw)   ))\n",
    "        update_w.append(tf.assign( self.vw,self.vw*beta2 + (1-beta2) * (gradw ** 2)   ))\n",
    "        m_hatw    = self.mw / (1-beta1)\n",
    "        v_hatw    = self.vw / (1-beta2)\n",
    "        adam_midw = m_hatw *  learning_rate/(tf.sqrt(v_hatw) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,self.sym_decorrelation(tf.subtract(self.w,adam_midw))))\n",
    "        \n",
    "        update_w.append(tf.assign( self.ma,self.ma*beta1 + (1-beta1) * (grada)   ))\n",
    "        update_w.append(tf.assign( self.va,self.va*beta2 + (1-beta2) * (grada ** 2)   ))\n",
    "        m_hata    = self.ma / (1-beta1)\n",
    "        v_hata    = self.va / (1-beta2)\n",
    "        adam_mida = m_hata *  learning_rate/(tf.sqrt(v_hata) + adam_e)\n",
    "        update_w.append(tf.assign(self.a,self.stand(tf.subtract(self.a,adam_mida))))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (gradb)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (gradb ** 2)   ))\n",
    "        m_hatb    = self.mb / (1-beta1)\n",
    "        v_hatb    = self.vb / (1-beta2)\n",
    "        adam_midb = m_hatb *  learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,self.stand(tf.subtract(self.b,adam_midb))))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mc,self.mc*beta1 + (1-beta1) * (gradc)   ))\n",
    "        update_w.append(tf.assign( self.vc,self.vc*beta2 + (1-beta2) * (gradc ** 2)   ))\n",
    "        m_hatc    = self.mc / (1-beta1)\n",
    "        v_hatc    = self.vc / (1-beta2)\n",
    "        adam_midc = m_hatb *  learning_rate/(tf.sqrt(v_hatc) + adam_e)\n",
    "        update_w.append(tf.assign(self.c,self.stand(tf.subtract(self.c,adam_midc))))\n",
    "\n",
    "        return grad_pass,update_w\n",
    "    \n",
    "    def stand(self,w):\n",
    "        mean,variance = tf.nn.moments(w,0)\n",
    "        return (w-mean)/variance\n",
    "    def norm(self,W):\n",
    "        W = W/(tf.sqrt(tf.reduce_sum(W**2)+1e-8))\n",
    "        return W\n",
    "    def sym_decorrelation(self,W):\n",
    "        s, u = tf.linalg.eigh(W@tf.transpose(W))\n",
    "        result = (u * (1./(tf.sqrt(s+1e-5)+1e-5))) @ tf.transpose(u) @ W\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T23:04:31.781847Z",
     "start_time": "2019-04-10T23:04:31.779342Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the hyper\n",
    "learning_rate = 0.000008\n",
    "beta1,beta2,adam_e = 0.9,0.999,1e-8\n",
    "mini_batch_size    = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-10T23:08:15.250Z"
    }
   },
   "outputs": [],
   "source": [
    "# create layers \n",
    "l1 = PCA_Layer(784,128)\n",
    "l2 = PCA_Layer(128,32)\n",
    "l3 = PCA_Layer(32,16)\n",
    "l4 = PCA_Layer(16,2)\n",
    "\n",
    "x = tf.placeholder(tf.float32,[mini_batch_size,784])\n",
    "\n",
    "layer1,l1l = l1.feedforward_nonlinear(x)\n",
    "layer2,l2l = l2.feedforward_nonlinear(layer1)\n",
    "layer3,l3l = l3.feedforward_nonlinear(layer2)\n",
    "layer4,l4l = l4.feedforward_linear(layer3)\n",
    "\n",
    "loss = tf.reduce_mean(l1l) + tf.reduce_mean(l2l) + tf.reduce_mean(l3l) + tf.reduce_mean(l4l)\n",
    "\n",
    "grad4,grad4_update = l4.backprop_linear()\n",
    "grad3,grad3_update = l3.backprop_nonlinear(grad4)\n",
    "grad2,grad2_update = l2.backprop_nonlinear(grad3)\n",
    "grad1,grad1_update = l1.backprop_nonlinear(grad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T23:06:02.123736Z",
     "start_time": "2019-04-10T23:05:44.315707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "3070\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "3150\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n",
      "3230\n",
      "3240\n",
      "3250\n",
      "3260\n",
      "3270\n",
      "3280\n",
      "3290\n",
      "3300\n",
      "3310\n",
      "3320\n",
      "3330\n",
      "3340\n",
      "3350\n",
      "3360\n",
      "3370\n",
      "3380\n",
      "3390\n",
      "3400\n",
      "3410\n",
      "3420\n",
      "3430\n",
      "3440\n",
      "3450\n",
      "3460\n",
      "3470\n",
      "3480\n",
      "3490\n",
      "3500\n",
      "3510\n",
      "3520\n",
      "3530\n",
      "3540\n",
      "3550\n",
      "3560\n",
      "3570\n",
      "3580\n",
      "3590\n",
      "3600\n",
      "3610\n",
      "3620\n",
      "3630\n",
      "3640\n",
      "3650\n",
      "3660\n",
      "3670\n",
      "3680\n",
      "3690\n",
      "3700\n",
      "3710\n",
      "3720\n",
      "3730\n",
      "3740\n",
      "3750\n",
      "3760\n",
      "3770\n",
      "3780\n",
      "3790\n",
      "3800\n",
      "3810\n",
      "3820\n",
      "3830\n",
      "3840\n",
      "3850\n",
      "3860\n",
      "3870\n",
      "3880\n",
      "3890\n",
      "3900\n",
      "3910\n",
      "3920\n",
      "3930\n",
      "3940\n",
      "3950\n",
      "3960\n",
      "3970\n",
      "3980\n",
      "3990\n",
      "4000\n",
      "4010\n",
      "4020\n",
      "4030\n",
      "4040\n",
      "4050\n",
      "4060\n",
      "4070\n",
      "4080\n",
      "4090\n",
      "4100\n",
      "4110\n",
      "4120\n",
      "4130\n",
      "4140\n",
      "4150\n",
      "4160\n",
      "4170\n",
      "4180\n",
      "4190\n",
      "4200\n",
      "4210\n",
      "4220\n",
      "4230\n",
      "4240\n",
      "4250\n",
      "4260\n",
      "4270\n",
      "4280\n",
      "4290\n",
      "4300\n",
      "4310\n",
      "4320\n",
      "4330\n",
      "4340\n",
      "4350\n",
      "4360\n",
      "4370\n",
      "4380\n",
      "4390\n",
      "4400\n",
      "4410\n",
      "4420\n",
      "4430\n",
      "4440\n",
      "4450\n",
      "4460\n",
      "4470\n",
      "4480\n",
      "4490\n",
      "4500\n",
      "4510\n",
      "4520\n",
      "4530\n",
      "4540\n",
      "4550\n",
      "4560\n",
      "4570\n",
      "4580\n",
      "4590\n",
      "4600\n",
      "4610\n",
      "4620\n",
      "4630\n",
      "4640\n",
      "4650\n",
      "4660\n",
      "4670\n",
      "4680\n",
      "4690\n",
      "4700\n",
      "4710\n",
      "4720\n",
      "4730\n",
      "4740\n",
      "4750\n",
      "4760\n",
      "4770\n",
      "4780\n",
      "4790\n",
      "4800\n",
      "4810\n",
      "4820\n",
      "4830\n",
      "4840\n",
      "4850\n",
      "4860\n",
      "4870\n",
      "4880\n",
      "4890\n",
      "4900\n",
      "4910\n",
      "4920\n",
      "4930\n",
      "4940\n",
      "4950\n",
      "4960\n",
      "4970\n",
      "4980\n",
      "4990\n"
     ]
    }
   ],
   "source": [
    "# start\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "val_data_copy = np.copy(val_data)\n",
    "\n",
    "for iter in range(1):\n",
    "    \n",
    "    val_data_copy  = shuffle(val_data_copy)\n",
    "    for current_batch_index in range(0,len(val_data_copy),mini_batch_size):\n",
    "        print(current_batch_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T10:13:09.161357Z",
     "start_time": "2019-04-10T10:13:09.155405Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T10:13:27.263042Z",
     "start_time": "2019-04-10T10:13:26.516084Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T10:11:52.719892Z",
     "start_time": "2019-04-10T10:11:52.713939Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
