{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T08:56:07.235562Z",
     "start_time": "2019-04-10T08:56:07.207294Z"
    },
    "code_folding": [
     22
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import make_moons,make_classification,make_regression,make_circles\n",
    "import sys\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "np.random.seed(23)\n",
    "np.set_printoptions(precision=3,suppress=True)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def _sym_decorrelation(W):\n",
    "    \"\"\" Symmetric decorrelation\n",
    "    i.e. W <- (W * W.T) ^{-1/2} * W\n",
    "    \"\"\"\n",
    "    s, u = np.linalg.eigh(np.dot(W, W.T))\n",
    "    # u (resp. s) contains the eigenvectors (resp. square roots of\n",
    "    # the eigenvalues) of W * W.T\n",
    "    return np.dot(np.dot(u * (1./(np.sqrt(s+1e-8))+1e-8), u.T), W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T08:56:09.781181Z",
     "start_time": "2019-04-10T08:56:09.261869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../Dataset/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ../../Dataset/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../Dataset/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../Dataset/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784) (55000, 10) 1.0 0.0\n",
      "(5000, 784) (5000, 10) 1.0 0.0\n",
      "(10000, 784) (10000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "mnist = input_data.read_data_sets('../../Dataset/MNIST/', one_hot=True)\n",
    "train_data,train_label,val_data,val_label,test_data,test_label = mnist.train.images,mnist.train.labels,mnist.validation.images,mnist.validation.labels,mnist.test.images, mnist.test.labels\n",
    "print(train_data.shape,train_label.shape,train_data.max(),train_data.min())\n",
    "print(val_data.shape,val_label.shape,val_data.max(),val_data.min())\n",
    "print(test_data.shape,test_label.shape,test_data.max(),test_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T09:07:05.072493Z",
     "start_time": "2019-04-10T09:07:05.052150Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning:\n",
      "\n",
      "An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start session \n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T09:00:43.436351Z",
     "start_time": "2019-04-10T09:00:43.427446Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#  create class\n",
    "def arctan(x):  return tf.arctan(x)\n",
    "def tan(x)   :  return tf.tan(x)\n",
    "def d_arctan(x):return 1/(1+x**2)\n",
    "def d_tanh(x):  return 1/tf.cos(x)\n",
    "\n",
    "class FNN():\n",
    "    \n",
    "    def __init__(self,input,output,act,d_act):\n",
    "        self.w = tf.Variable(tf.random.normal())\n",
    "        self.mw,self.mv = np.zeros_like()\n",
    "        \n",
    "        self.a = np.ones(output)\n",
    "        self.b = np.ones(output)\n",
    "        self.c = np.zeros(output)\n",
    "        \n",
    "        self.act  = act\n",
    "        self.d_act= d_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T10:02:57.684867Z",
     "start_time": "2019-04-10T10:02:57.666530Z"
    },
    "code_folding": [
     31,
     34,
     56
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tf_arctan(x): return tf.atan(x)\n",
    "def tf_tan(x)   : return tf.tan(x)\n",
    "\n",
    "def d_tf_arctan(x): return 1/(1+x**2)\n",
    "def d_tf_tan(x):    return 1/(tf.cos(x)**2)\n",
    "\n",
    "class PCA_Layer():\n",
    "\n",
    "    def __init__(self,inc,outc,act=tf_arctan,d_act=d_tf_arctan):\n",
    "        \n",
    "        if outc == 1:\n",
    "            self.w = self.norm(tf.Variable(tf.random_normal([inc,outc],stddev=1,seed=2)))\n",
    "        else:\n",
    "            self.w = tf.Variable(tf.random_normal([inc,outc],stddev=0.05,seed=2))\n",
    "        self.a = tf.Variable(tf.ones([outc]))\n",
    "        self.b = tf.Variable(tf.ones([outc]))\n",
    "        self.c = tf.Variable(tf.zeros([outc]))\n",
    "        \n",
    "        self.mw,self.vw = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.ma,self.va = tf.Variable(tf.zeros_like(self.a)),tf.Variable(tf.zeros_like(self.a))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.mc,self.vc = tf.Variable(tf.zeros_like(self.c)),tf.Variable(tf.zeros_like(self.c))\n",
    "        \n",
    "        self.act,self.d_act = act,d_act\n",
    "\n",
    "    def feedforward(self,input=None):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.matmul(self.input,self.w) \n",
    "        self.layerA = self.a*self.act(self.b*self.layer) + self.c\n",
    "        return self.layerA\n",
    "    \n",
    "    def backprop_first(self):\n",
    "        pass \n",
    "\n",
    "    def backprop(self,gradient=None,which_reg=0):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad  = tf.matmul(tf.transpose(grad_part_3),grad_middle)/batch_size\n",
    "        grad_b= tf.reduce_mean(grad_middle,axis=0)\n",
    "        grad_pass = tf.matmul(grad_middle,tf.transpose(self.w))\n",
    "\n",
    "        update_w = []\n",
    "\n",
    "        # Update the Weight First\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1)\n",
    "        v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat *  learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle )))\n",
    "\n",
    "        return grad_pass,update_w\n",
    "    \n",
    "    def norm(self,W):\n",
    "        W = W/(tf.sqrt(tf.reduce_sum(W**2)+1e-8))\n",
    "        return W\n",
    "    \n",
    "    def sym_decorrelation(self,W):\n",
    "        s, u = tf.linalg.eigh(W@tf.transpose(W))\n",
    "        result = (u * (1./(tf.sqrt(s+1e-8)+1e-8)) @ tf.transpose(u) @ W\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T10:02:58.242352Z",
     "start_time": "2019-04-10T10:02:57.957110Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.ones((10,784)).astype(np.float32)\n",
    "               \n",
    "layer1 = PCA_Layer(784,256)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "te = layer1.w.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T10:03:47.117246Z",
     "start_time": "2019-04-10T10:03:46.111146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     0.     0.     0.     0.38   0.39\n",
      "  0.405  0.413  0.433  0.435  0.447  0.457  0.468  0.485  0.498  0.507\n",
      "  0.523  0.527  0.531  0.547  0.561  0.569  0.576  0.582  0.593  0.603\n",
      "  0.615  0.622  0.627  0.632  0.647  0.658  0.666  0.671  0.675  0.686\n",
      "  0.687  0.699  0.71   0.713  0.74   0.746  0.751  0.761  0.768  0.784\n",
      "  0.801  0.817  0.826  0.83   0.836  0.837  0.839  0.861  0.872  0.88\n",
      "  0.895  0.906  0.915  0.924  0.929  0.932  0.955  0.958  0.976  0.995\n",
      "  1.004  1.008  1.019  1.033  1.036  1.043  1.059  1.07   1.077  1.08\n",
      "  1.096  1.113  1.128  1.134  1.143  1.151  1.162  1.173  1.194  1.198\n",
      "  1.211  1.22   1.226  1.242  1.256  1.265  1.27   1.28   1.309  1.314\n",
      "  1.318  1.335  1.343  1.35   1.366  1.378  1.384  1.407  1.417  1.42\n",
      "  1.44   1.448  1.46   1.47   1.48   1.494  1.5    1.514  1.525  1.533\n",
      "  1.543  1.549  1.565  1.586  1.603  1.61   1.628  1.636  1.652  1.682\n",
      "  1.685  1.694  1.714  1.733  1.735  1.747  1.777  1.792  1.795  1.809\n",
      "  1.826  1.831  1.852  1.859  1.884  1.888  1.897  1.906  1.921  1.93\n",
      "  1.938  1.944  1.978  1.982  1.983  2.011  2.031  2.04   2.054  2.077\n",
      "  2.088  2.115  2.122  2.137  2.154  2.172  2.194  2.205  2.219  2.233\n",
      "  2.245  2.258  2.269  2.294  2.317  2.333  2.345  2.364  2.408  2.416\n",
      "  2.438  2.448  2.465  2.472  2.488  2.507  2.514  2.531  2.548  2.553\n",
      "  2.576  2.585  2.632  2.644  2.649  2.652  2.704  2.713  2.734  2.757\n",
      "  2.764  2.782  2.811  2.834  2.851  2.854  2.883  2.9    2.92   2.938\n",
      "  2.97   2.979  2.997  3.023  3.055  3.089  3.127  3.144  3.153  3.178\n",
      "  3.201  3.234  3.235  3.267  3.282  3.311  3.324  3.341  3.355  3.423\n",
      "  3.446  3.449  3.476  3.517  3.538  3.567  3.594  3.625  3.67   3.699\n",
      "  3.735  3.74   3.778  3.797  3.849  3.861  3.897  3.928  3.943  3.993\n",
      "  4.031  4.065  4.125  4.142  4.211  4.252  4.322  4.364  4.406  4.443\n",
      "  4.569  4.614  4.701  4.852]\n",
      "[[ 0.177  0.041 -0.214 ...  0.014 -0.037  0.043]\n",
      " [-0.273 -0.082  0.263 ... -0.006 -0.027  0.008]\n",
      " [ 0.053 -0.019 -0.088 ...  0.05  -0.005  0.019]\n",
      " ...\n",
      " [ 0.004  0.02   0.062 ... -0.012  0.017  0.013]\n",
      " [ 0.016  0.034  0.032 ... -0.002 -0.007  0.039]\n",
      " [ 0.039  0.016  0.003 ... -0.014 -0.015 -0.005]]\n"
     ]
    }
   ],
   "source": [
    "te.shape\n",
    "\n",
    "s, u = tf.linalg.eigh(te@te.T)\n",
    "print(s.eval())\n",
    "print(u.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T10:00:50.408466Z",
     "start_time": "2019-04-10T10:00:50.402973Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T10:07:29.437666Z",
     "start_time": "2019-04-10T10:07:29.344444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -0. -0. ... -0. -0.  0.]\n",
      " [-0.  1. -0. ...  0. -0.  0.]\n",
      " [-0. -0.  1. ... -0.  0.  0.]\n",
      " ...\n",
      " [-0.  0. -0. ...  1.  0. -0.]\n",
      " [-0. -0.  0. ...  0.  1.  0.]\n",
      " [ 0.  0.  0. ... -0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "ss  =np.random.randn(784,256)\n",
    "def _sym_decorrelation(W):\n",
    "    \"\"\" Symmetric decorrelation\n",
    "    i.e. W <- (W * W.T) ^{-1/2} * W\n",
    "    \"\"\"\n",
    "    s, u = np.linalg.eigh(np.dot(W, W.T))\n",
    "    # u (resp. s) contains the eigenvectors (resp. square roots of\n",
    "    # the eigenvalues) of W * W.T\n",
    "    return (u * (1./(np.sqrt(s+1e-8)+1e-8))) @ u.T @ W\n",
    "\n",
    "sss = _sym_decorrelation(ss)\n",
    "print(sss.T@sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
